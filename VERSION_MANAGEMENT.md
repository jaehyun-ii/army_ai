# Version Management Guide

## ðŸ“‹ Version Overview

### **Backend (Python 3.12)**

| Component | Version | Managed By |
|-----------|---------|------------|
| **Python** | 3.12 | Dockerfile base image |
| **PyTorch** | 2.3.0 | requirements.txt |
| **CUDA** | 12.1 | Dockerfile base image (GPU) |
| **cuDNN** | 8 | Dockerfile base image (GPU) |
| **FastAPI** | â‰¥0.115.0 | requirements.txt |
| **SQLAlchemy** | â‰¥2.0.36 | requirements.txt |
| **NumPy** | â‰¥2.0.0, <3.0.0 | requirements.txt |

### **Frontend (Node.js 18)**

| Component | Version | Managed By |
|-----------|---------|------------|
| **Node.js** | 18 LTS | Dockerfile base image |
| **Next.js** | 14 | package.json |
| **React** | 18 | package.json |
| **TypeScript** | 5.9 | package.json |

### **Database**

| Component | Version | Managed By |
|-----------|---------|------------|
| **PostgreSQL** | 15 | docker-compose.yml |

---

## ðŸ”§ How Versions Are Managed

### **1. Python Version (Dockerfile)**

```dockerfile
# CPU-only
FROM python:3.12-slim

# GPU-enabled
FROM nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04
# Then install Python 3.12 manually
```

**To change Python version:**
1. Edit `backend/Dockerfile` (CPU) or `backend/Dockerfile.gpu` (GPU)
2. Change base image version
3. Rebuild: `docker-compose build backend`

---

### **2. PyTorch & CUDA Version (requirements.txt)**

```txt
# CPU-only (Option 1)
torch==2.3.0
torchvision==0.18.0
torchaudio==2.3.0

# GPU with CUDA 12.1 (Option 2)
torch==2.3.0+cu121
torchvision==0.18.0+cu121
torchaudio==2.3.0+cu121
--extra-index-url https://download.pytorch.org/whl/cu121
```

**Available CUDA versions:**
- `cu121` - CUDA 12.1 (í˜„ìž¬ ì‚¬ìš©)
- `cu118` - CUDA 11.8
- CPU-only (no suffix)

**To change PyTorch/CUDA version:**
1. Edit `backend/requirements.txt`
2. Comment out current version
3. Uncomment desired version
4. If using GPU, update `Dockerfile.gpu` base image to match CUDA version
5. Rebuild: `docker-compose -f docker-compose.gpu.yml build`

**PyTorch version compatibility:**
```bash
# Check available versions at:
https://pytorch.org/get-started/previous-versions/

# Example for PyTorch 2.4 with CUDA 12.1:
torch==2.4.0+cu121
torchvision==0.19.0+cu121
--extra-index-url https://download.pytorch.org/whl/cu121
```

---

### **3. Node.js Version (Dockerfile)**

```dockerfile
FROM node:18-alpine
```

**To change Node.js version:**
1. Edit `frontend/Dockerfile`
2. Change to desired LTS version (16, 18, 20, etc.)
3. Rebuild: `docker-compose build frontend`

---

### **4. Database Version (docker-compose.yml)**

```yaml
postgres:
  image: postgres:15-alpine
```

**To change PostgreSQL version:**
1. Edit `docker-compose.yml`
2. Change image tag (13, 14, 15, 16)
3. Stop and remove old container
4. Start with new version

**âš ï¸ Warning:** Major PostgreSQL version upgrades may require data migration!

---

## ðŸŽ¯ Deployment Scenarios

### **Scenario 1: CPU-Only Deployment**

```bash
# 1. Edit requirements.txt - use CPU versions
torch==2.3.0
torchvision==0.18.0

# 2. Use standard docker-compose
docker-compose build
docker-compose up -d
```

**Pros:** Works anywhere, smaller image size
**Cons:** Slower inference (~10-50x slower than GPU)

---

### **Scenario 2: GPU Deployment (Recommended)**

```bash
# 1. Prerequisites
# - NVIDIA GPU
# - NVIDIA Driver installed
# - nvidia-docker2 installed

# 2. Verify NVIDIA Docker
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi

# 3. Edit requirements.txt - use GPU versions
torch==2.3.0+cu121
torchvision==0.18.0+cu121
--extra-index-url https://download.pytorch.org/whl/cu121

# 4. Use GPU docker-compose
docker-compose -f docker-compose.gpu.yml build
docker-compose -f docker-compose.gpu.yml up -d
```

**Pros:** Fast inference, optimal for production
**Cons:** Requires NVIDIA GPU, larger image size

---

## ðŸ“¦ Version Lock Files

### **Backend - requirements.txt**
- **Purpose:** Define all Python package versions
- **Format:** `package>=min_version` or `package==exact_version`
- **Lock file:** Can generate with `pip freeze > requirements-lock.txt`

### **Frontend - package.json + package-lock.json**
- **package.json:** Define dependencies and version ranges
- **package-lock.json:** Exact versions (auto-generated by npm)
- **Committed:** Yes, always commit package-lock.json

---

## ðŸ”„ Updating Versions

### **Update PyTorch**

```bash
# 1. Check current version
docker-compose exec backend python -c "import torch; print(torch.__version__)"

# 2. Edit requirements.txt
torch==2.4.0+cu121  # Update version

# 3. Rebuild
docker-compose build backend
docker-compose up -d backend
```

### **Update Node.js packages**

```bash
# Check outdated packages
cd frontend
npm outdated

# Update specific package
npm install next@latest

# Update all packages (careful!)
npm update

# Rebuild
docker-compose build frontend
docker-compose up -d frontend
```

---

## ðŸ§ª Version Verification

### **Check installed versions inside containers**

```bash
# Backend Python/PyTorch versions
docker-compose exec backend python --version
docker-compose exec backend python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"

# Frontend Node.js version
docker-compose exec frontend node --version
docker-compose exec frontend npm --version

# Database version
docker-compose exec postgres psql --version
```

### **Test GPU availability**

```bash
docker-compose -f docker-compose.gpu.yml exec backend python -c "
import torch
print(f'CUDA Available: {torch.cuda.is_available()}')
print(f'CUDA Device Count: {torch.cuda.device_count()}')
if torch.cuda.is_available():
    print(f'CUDA Device: {torch.cuda.get_device_name(0)}')
"
```

---

## ðŸ“ Best Practices

1. **Pin exact versions in production**
   ```txt
   # Development (flexible)
   torch>=2.3.0

   # Production (locked)
   torch==2.3.0+cu121
   ```

2. **Test before updating major versions**
   - Create a test environment
   - Run full test suite
   - Check for breaking changes

3. **Document version changes**
   - Update this file
   - Add to git commit message
   - Note any breaking changes

4. **Keep CUDA version consistent**
   - PyTorch CUDA version (cu121)
   - Dockerfile base image (cuda:12.1.0)
   - System NVIDIA driver (â‰¥12.1)

---

## ðŸ†˜ Troubleshooting

### **PyTorch CUDA version mismatch**

```bash
# Error: CUDA version mismatch
RuntimeError: CUDA runtime version X.X doesn't match PyTorch built with Y.Y

# Solution: Match versions in requirements.txt and Dockerfile.gpu
# Example for CUDA 12.1:
# Dockerfile.gpu: nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04
# requirements.txt: torch==2.3.0+cu121
```

### **Package conflicts**

```bash
# Error: Package version conflicts
ERROR: pip's dependency resolver...

# Solution: Use exact versions or compatible ranges
# Check compatibility at: https://pypi.org/project/torch/
```

---

## ðŸ“š References

- **PyTorch versions:** https://pytorch.org/get-started/previous-versions/
- **CUDA compatibility:** https://docs.nvidia.com/deploy/cuda-compatibility/
- **Node.js releases:** https://nodejs.org/en/about/previous-releases
- **PostgreSQL versions:** https://www.postgresql.org/support/versioning/
